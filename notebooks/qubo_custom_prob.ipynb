{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/Users/linusrandud/Documents/UoM/ERP/MscDissertation/Deep-Opt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from COProblems.MKP import MKP\n",
    "from COProblems.QUBO import QUBO\n",
    "from Models.DOAE import DOAE\n",
    "from OptimAE import OptimAEHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Highly recommended to keep as cpu for problems of size <= 100\n",
    "device=\"cpu\"\n",
    "print(device)\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = [13, 23, 13, 13, 13, 13, 13, 13, 23, 13, 10, 10, 10, 20, 25, 20, 10, 15, 10, 20]\n",
    "# durations = [13, 23,16, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem converter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qubo_matrix(durations):\n",
    "    \"\"\"\n",
    "    Generate a QUBO matrix for the given job durations.\n",
    "\n",
    "    Parameters:\n",
    "    durations (list): List of job durations.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The QUBO matrix as a PyTorch tensor.\n",
    "    \"\"\"\n",
    "    # Number of jobs\n",
    "    n = len(durations)\n",
    "\n",
    "    # Initialize QUBO matrix\n",
    "    Q = np.zeros((n, n))\n",
    "\n",
    "    # Fill the QUBO matrix\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            if i == j:\n",
    "                Q[i, j] = durations[i] ** 2\n",
    "            else:\n",
    "                Q[i, j] = 2 * durations[i] * durations[j]\n",
    "\n",
    "    # Convert Q matrix to PyTorch tensor and negate for minimization\n",
    "    Q = -Q\n",
    "    Q_tensor = torch.tensor(Q)\n",
    "\n",
    "    return Q_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = generate_qubo_matrix(durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -169.,  -598.,  -338.,  -338.,  -338.,  -338.,  -338.,  -338.,  -598.,\n",
       "          -338.,  -260.,  -260.,  -260.,  -520.,  -650.,  -520.,  -260.,  -390.,\n",
       "          -260.,  -520.],\n",
       "        [   -0.,  -529.,  -598.,  -598.,  -598.,  -598.,  -598.,  -598., -1058.,\n",
       "          -598.,  -460.,  -460.,  -460.,  -920., -1150.,  -920.,  -460.,  -690.,\n",
       "          -460.,  -920.],\n",
       "        [   -0.,    -0.,  -169.,  -338.,  -338.,  -338.,  -338.,  -338.,  -598.,\n",
       "          -338.,  -260.,  -260.,  -260.,  -520.,  -650.,  -520.,  -260.,  -390.,\n",
       "          -260.,  -520.],\n",
       "        [   -0.,    -0.,    -0.,  -169.,  -338.,  -338.,  -338.,  -338.,  -598.,\n",
       "          -338.,  -260.,  -260.,  -260.,  -520.,  -650.,  -520.,  -260.,  -390.,\n",
       "          -260.,  -520.],\n",
       "        [   -0.,    -0.,    -0.,    -0.,  -169.,  -338.,  -338.,  -338.,  -598.,\n",
       "          -338.,  -260.,  -260.,  -260.,  -520.,  -650.,  -520.,  -260.,  -390.,\n",
       "          -260.,  -520.],\n",
       "        [   -0.,    -0.,    -0.,    -0.,    -0.,  -169.,  -338.,  -338.,  -598.,\n",
       "          -338.,  -260.,  -260.,  -260.,  -520.,  -650.,  -520.,  -260.,  -390.,\n",
       "          -260.,  -520.],\n",
       "        [   -0.,    -0.,    -0.,    -0.,    -0.,    -0.,  -169.,  -338.,  -598.,\n",
       "          -338.,  -260.,  -260.,  -260.,  -520.,  -650.,  -520.,  -260.,  -390.,\n",
       "          -260.,  -520.],\n",
       "        [   -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,  -169.,  -598.,\n",
       "          -338.,  -260.,  -260.,  -260.,  -520.,  -650.,  -520.,  -260.,  -390.,\n",
       "          -260.,  -520.],\n",
       "        [   -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,  -529.,\n",
       "          -598.,  -460.,  -460.,  -460.,  -920., -1150.,  -920.,  -460.,  -690.,\n",
       "          -460.,  -920.],\n",
       "        [   -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,\n",
       "          -169.,  -260.,  -260.,  -260.,  -520.,  -650.,  -520.,  -260.,  -390.,\n",
       "          -260.,  -520.],\n",
       "        [   -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,\n",
       "            -0.,  -100.,  -200.,  -200.,  -400.,  -500.,  -400.,  -200.,  -300.,\n",
       "          -200.,  -400.],\n",
       "        [   -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,\n",
       "            -0.,    -0.,  -100.,  -200.,  -400.,  -500.,  -400.,  -200.,  -300.,\n",
       "          -200.,  -400.],\n",
       "        [   -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,\n",
       "            -0.,    -0.,    -0.,  -100.,  -400.,  -500.,  -400.,  -200.,  -300.,\n",
       "          -200.,  -400.],\n",
       "        [   -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,\n",
       "            -0.,    -0.,    -0.,    -0.,  -400., -1000.,  -800.,  -400.,  -600.,\n",
       "          -400.,  -800.],\n",
       "        [   -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,\n",
       "            -0.,    -0.,    -0.,    -0.,    -0.,  -625., -1000.,  -500.,  -750.,\n",
       "          -500., -1000.],\n",
       "        [   -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,\n",
       "            -0.,    -0.,    -0.,    -0.,    -0.,    -0.,  -400.,  -400.,  -600.,\n",
       "          -400.,  -800.],\n",
       "        [   -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,\n",
       "            -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,  -100.,  -300.,\n",
       "          -200.,  -400.],\n",
       "        [   -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,\n",
       "            -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,  -225.,\n",
       "          -300.,  -600.],\n",
       "        [   -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,\n",
       "            -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,\n",
       "          -100.,  -400.],\n",
       "        [   -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,\n",
       "            -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,    -0.,\n",
       "            -0.,  -400.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qubo_matrix(arr):\n",
    "    n = len(arr)\n",
    "    A = sum(arr)\n",
    "    Q = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            if i == j:\n",
    "                Q[i, j] = 4 * arr[i] ** 2 - 4 * A * arr[i]\n",
    "            else:\n",
    "                Q[i, j] = Q[j, i] = 8 * arr[i] * arr[j]\n",
    "    \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = generate_qubo_matrix(durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-14924.,   2392.,   1352.,   1352.,   1352.,   1352.,   1352.,\n",
       "          1352.,   2392.,   1352.,   1040.,   1040.,   1040.,   2080.,\n",
       "          2600.,   2080.,   1040.,   1560.,   1040.,   2080.],\n",
       "       [  2392., -25484.,   2392.,   2392.,   2392.,   2392.,   2392.,\n",
       "          2392.,   4232.,   2392.,   1840.,   1840.,   1840.,   3680.,\n",
       "          4600.,   3680.,   1840.,   2760.,   1840.,   3680.],\n",
       "       [  1352.,   2392., -14924.,   1352.,   1352.,   1352.,   1352.,\n",
       "          1352.,   2392.,   1352.,   1040.,   1040.,   1040.,   2080.,\n",
       "          2600.,   2080.,   1040.,   1560.,   1040.,   2080.],\n",
       "       [  1352.,   2392.,   1352., -14924.,   1352.,   1352.,   1352.,\n",
       "          1352.,   2392.,   1352.,   1040.,   1040.,   1040.,   2080.,\n",
       "          2600.,   2080.,   1040.,   1560.,   1040.,   2080.],\n",
       "       [  1352.,   2392.,   1352.,   1352., -14924.,   1352.,   1352.,\n",
       "          1352.,   2392.,   1352.,   1040.,   1040.,   1040.,   2080.,\n",
       "          2600.,   2080.,   1040.,   1560.,   1040.,   2080.],\n",
       "       [  1352.,   2392.,   1352.,   1352.,   1352., -14924.,   1352.,\n",
       "          1352.,   2392.,   1352.,   1040.,   1040.,   1040.,   2080.,\n",
       "          2600.,   2080.,   1040.,   1560.,   1040.,   2080.],\n",
       "       [  1352.,   2392.,   1352.,   1352.,   1352.,   1352., -14924.,\n",
       "          1352.,   2392.,   1352.,   1040.,   1040.,   1040.,   2080.,\n",
       "          2600.,   2080.,   1040.,   1560.,   1040.,   2080.],\n",
       "       [  1352.,   2392.,   1352.,   1352.,   1352.,   1352.,   1352.,\n",
       "        -14924.,   2392.,   1352.,   1040.,   1040.,   1040.,   2080.,\n",
       "          2600.,   2080.,   1040.,   1560.,   1040.,   2080.],\n",
       "       [  2392.,   4232.,   2392.,   2392.,   2392.,   2392.,   2392.,\n",
       "          2392., -25484.,   2392.,   1840.,   1840.,   1840.,   3680.,\n",
       "          4600.,   3680.,   1840.,   2760.,   1840.,   3680.],\n",
       "       [  1352.,   2392.,   1352.,   1352.,   1352.,   1352.,   1352.,\n",
       "          1352.,   2392., -14924.,   1040.,   1040.,   1040.,   2080.,\n",
       "          2600.,   2080.,   1040.,   1560.,   1040.,   2080.],\n",
       "       [  1040.,   1840.,   1040.,   1040.,   1040.,   1040.,   1040.,\n",
       "          1040.,   1840.,   1040., -11600.,    800.,    800.,   1600.,\n",
       "          2000.,   1600.,    800.,   1200.,    800.,   1600.],\n",
       "       [  1040.,   1840.,   1040.,   1040.,   1040.,   1040.,   1040.,\n",
       "          1040.,   1840.,   1040.,    800., -11600.,    800.,   1600.,\n",
       "          2000.,   1600.,    800.,   1200.,    800.,   1600.],\n",
       "       [  1040.,   1840.,   1040.,   1040.,   1040.,   1040.,   1040.,\n",
       "          1040.,   1840.,   1040.,    800.,    800., -11600.,   1600.,\n",
       "          2000.,   1600.,    800.,   1200.,    800.,   1600.],\n",
       "       [  2080.,   3680.,   2080.,   2080.,   2080.,   2080.,   2080.,\n",
       "          2080.,   3680.,   2080.,   1600.,   1600.,   1600., -22400.,\n",
       "          4000.,   3200.,   1600.,   2400.,   1600.,   3200.],\n",
       "       [  2600.,   4600.,   2600.,   2600.,   2600.,   2600.,   2600.,\n",
       "          2600.,   4600.,   2600.,   2000.,   2000.,   2000.,   4000.,\n",
       "        -27500.,   4000.,   2000.,   3000.,   2000.,   4000.],\n",
       "       [  2080.,   3680.,   2080.,   2080.,   2080.,   2080.,   2080.,\n",
       "          2080.,   3680.,   2080.,   1600.,   1600.,   1600.,   3200.,\n",
       "          4000., -22400.,   1600.,   2400.,   1600.,   3200.],\n",
       "       [  1040.,   1840.,   1040.,   1040.,   1040.,   1040.,   1040.,\n",
       "          1040.,   1840.,   1040.,    800.,    800.,    800.,   1600.,\n",
       "          2000.,   1600., -11600.,   1200.,    800.,   1600.],\n",
       "       [  1560.,   2760.,   1560.,   1560.,   1560.,   1560.,   1560.,\n",
       "          1560.,   2760.,   1560.,   1200.,   1200.,   1200.,   2400.,\n",
       "          3000.,   2400.,   1200., -17100.,   1200.,   2400.],\n",
       "       [  1040.,   1840.,   1040.,   1040.,   1040.,   1040.,   1040.,\n",
       "          1040.,   1840.,   1040.,    800.,    800.,    800.,   1600.,\n",
       "          2000.,   1600.,    800.,   1200., -11600.,   1600.],\n",
       "       [  2080.,   3680.,   2080.,   2080.,   2080.,   2080.,   2080.,\n",
       "          2080.,   3680.,   2080.,   1600.,   1600.,   1600.,   3200.,\n",
       "          4000.,   3200.,   1600.,   2400.,   1600., -22400.]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qubo_matrix(S):\n",
    "    n = len(S)\n",
    "    c = sum(S)\n",
    "    Q = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                Q[i, j] = S[i] * (S[i] - c)\n",
    "            else:\n",
    "                Q[i, j] = S[i] * S[j]\n",
    "    \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = generate_qubo_matrix(durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3731.,   299.,   169.,   169.,   169.,   169.,   169.,   169.,\n",
       "          299.,   169.,   130.,   130.,   130.,   260.,   325.,   260.,\n",
       "          130.,   195.,   130.,   260.],\n",
       "       [  299., -6371.,   299.,   299.,   299.,   299.,   299.,   299.,\n",
       "          529.,   299.,   230.,   230.,   230.,   460.,   575.,   460.,\n",
       "          230.,   345.,   230.,   460.],\n",
       "       [  169.,   299., -3731.,   169.,   169.,   169.,   169.,   169.,\n",
       "          299.,   169.,   130.,   130.,   130.,   260.,   325.,   260.,\n",
       "          130.,   195.,   130.,   260.],\n",
       "       [  169.,   299.,   169., -3731.,   169.,   169.,   169.,   169.,\n",
       "          299.,   169.,   130.,   130.,   130.,   260.,   325.,   260.,\n",
       "          130.,   195.,   130.,   260.],\n",
       "       [  169.,   299.,   169.,   169., -3731.,   169.,   169.,   169.,\n",
       "          299.,   169.,   130.,   130.,   130.,   260.,   325.,   260.,\n",
       "          130.,   195.,   130.,   260.],\n",
       "       [  169.,   299.,   169.,   169.,   169., -3731.,   169.,   169.,\n",
       "          299.,   169.,   130.,   130.,   130.,   260.,   325.,   260.,\n",
       "          130.,   195.,   130.,   260.],\n",
       "       [  169.,   299.,   169.,   169.,   169.,   169., -3731.,   169.,\n",
       "          299.,   169.,   130.,   130.,   130.,   260.,   325.,   260.,\n",
       "          130.,   195.,   130.,   260.],\n",
       "       [  169.,   299.,   169.,   169.,   169.,   169.,   169., -3731.,\n",
       "          299.,   169.,   130.,   130.,   130.,   260.,   325.,   260.,\n",
       "          130.,   195.,   130.,   260.],\n",
       "       [  299.,   529.,   299.,   299.,   299.,   299.,   299.,   299.,\n",
       "        -6371.,   299.,   230.,   230.,   230.,   460.,   575.,   460.,\n",
       "          230.,   345.,   230.,   460.],\n",
       "       [  169.,   299.,   169.,   169.,   169.,   169.,   169.,   169.,\n",
       "          299., -3731.,   130.,   130.,   130.,   260.,   325.,   260.,\n",
       "          130.,   195.,   130.,   260.],\n",
       "       [  130.,   230.,   130.,   130.,   130.,   130.,   130.,   130.,\n",
       "          230.,   130., -2900.,   100.,   100.,   200.,   250.,   200.,\n",
       "          100.,   150.,   100.,   200.],\n",
       "       [  130.,   230.,   130.,   130.,   130.,   130.,   130.,   130.,\n",
       "          230.,   130.,   100., -2900.,   100.,   200.,   250.,   200.,\n",
       "          100.,   150.,   100.,   200.],\n",
       "       [  130.,   230.,   130.,   130.,   130.,   130.,   130.,   130.,\n",
       "          230.,   130.,   100.,   100., -2900.,   200.,   250.,   200.,\n",
       "          100.,   150.,   100.,   200.],\n",
       "       [  260.,   460.,   260.,   260.,   260.,   260.,   260.,   260.,\n",
       "          460.,   260.,   200.,   200.,   200., -5600.,   500.,   400.,\n",
       "          200.,   300.,   200.,   400.],\n",
       "       [  325.,   575.,   325.,   325.,   325.,   325.,   325.,   325.,\n",
       "          575.,   325.,   250.,   250.,   250.,   500., -6875.,   500.,\n",
       "          250.,   375.,   250.,   500.],\n",
       "       [  260.,   460.,   260.,   260.,   260.,   260.,   260.,   260.,\n",
       "          460.,   260.,   200.,   200.,   200.,   400.,   500., -5600.,\n",
       "          200.,   300.,   200.,   400.],\n",
       "       [  130.,   230.,   130.,   130.,   130.,   130.,   130.,   130.,\n",
       "          230.,   130.,   100.,   100.,   100.,   200.,   250.,   200.,\n",
       "        -2900.,   150.,   100.,   200.],\n",
       "       [  195.,   345.,   195.,   195.,   195.,   195.,   195.,   195.,\n",
       "          345.,   195.,   150.,   150.,   150.,   300.,   375.,   300.,\n",
       "          150., -4275.,   150.,   300.],\n",
       "       [  130.,   230.,   130.,   130.,   130.,   130.,   130.,   130.,\n",
       "          230.,   130.,   100.,   100.,   100.,   200.,   250.,   200.,\n",
       "          100.,   150., -2900.,   200.],\n",
       "       [  260.,   460.,   260.,   260.,   260.,   260.,   260.,   260.,\n",
       "          460.,   260.,   200.,   200.,   200.,   400.,   500.,   400.,\n",
       "          200.,   300.,   200., -5600.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the text file content\n",
    "lines = []\n",
    "lines.append(\"1\\n\")  # Number of problem instances\n",
    "\n",
    "# Collect non-zero entries\n",
    "n = Q.shape[0]\n",
    "non_zero_entries = []\n",
    "for i in range(n):\n",
    "    for j in range(i, n):\n",
    "        if Q[i][j] != 0:\n",
    "            non_zero_entries.append((i + 1, j + 1, int(Q[i][j])))\n",
    "\n",
    "# Add the number of variables and number of non-zero entries\n",
    "lines.append(f\"{n} {len(non_zero_entries)}\\n\")\n",
    "\n",
    "# Add the non-zero entries to lines\n",
    "for entry in non_zero_entries:\n",
    "    i, j, value = entry\n",
    "    lines.append(f\"{i} {j} {value}\\n\")\n",
    "\n",
    "# Write to file\n",
    "with open(\"../data/qubo/tpp_qubo20.txt\", \"w\") as f:\n",
    "    f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance has been loaded\n"
     ]
    }
   ],
   "source": [
    "problem = QUBO(\"../data/qubo/qubo_problem_small.txt\", 0, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<COProblems.QUBO.QUBO at 0x10edb79a0>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3731.,   299.,   169.,   169.,   169.,   169.,   169.,   169.,   299.,\n",
       "           169.,   130.,   130.,   130.,   260.,   325.,   260.,   130.,   195.,\n",
       "           130.,   260.],\n",
       "        [  299., -6371.,   299.,   299.,   299.,   299.,   299.,   299.,   529.,\n",
       "           299.,   230.,   230.,   230.,   460.,   575.,   460.,   230.,   345.,\n",
       "           230.,   460.],\n",
       "        [  169.,   299., -3731.,   169.,   169.,   169.,   169.,   169.,   299.,\n",
       "           169.,   130.,   130.,   130.,   260.,   325.,   260.,   130.,   195.,\n",
       "           130.,   260.],\n",
       "        [  169.,   299.,   169., -3731.,   169.,   169.,   169.,   169.,   299.,\n",
       "           169.,   130.,   130.,   130.,   260.,   325.,   260.,   130.,   195.,\n",
       "           130.,   260.],\n",
       "        [  169.,   299.,   169.,   169., -3731.,   169.,   169.,   169.,   299.,\n",
       "           169.,   130.,   130.,   130.,   260.,   325.,   260.,   130.,   195.,\n",
       "           130.,   260.],\n",
       "        [  169.,   299.,   169.,   169.,   169., -3731.,   169.,   169.,   299.,\n",
       "           169.,   130.,   130.,   130.,   260.,   325.,   260.,   130.,   195.,\n",
       "           130.,   260.],\n",
       "        [  169.,   299.,   169.,   169.,   169.,   169., -3731.,   169.,   299.,\n",
       "           169.,   130.,   130.,   130.,   260.,   325.,   260.,   130.,   195.,\n",
       "           130.,   260.],\n",
       "        [  169.,   299.,   169.,   169.,   169.,   169.,   169., -3731.,   299.,\n",
       "           169.,   130.,   130.,   130.,   260.,   325.,   260.,   130.,   195.,\n",
       "           130.,   260.],\n",
       "        [  299.,   529.,   299.,   299.,   299.,   299.,   299.,   299., -6371.,\n",
       "           299.,   230.,   230.,   230.,   460.,   575.,   460.,   230.,   345.,\n",
       "           230.,   460.],\n",
       "        [  169.,   299.,   169.,   169.,   169.,   169.,   169.,   169.,   299.,\n",
       "         -3731.,   130.,   130.,   130.,   260.,   325.,   260.,   130.,   195.,\n",
       "           130.,   260.],\n",
       "        [  130.,   230.,   130.,   130.,   130.,   130.,   130.,   130.,   230.,\n",
       "           130., -2900.,   100.,   100.,   200.,   250.,   200.,   100.,   150.,\n",
       "           100.,   200.],\n",
       "        [  130.,   230.,   130.,   130.,   130.,   130.,   130.,   130.,   230.,\n",
       "           130.,   100., -2900.,   100.,   200.,   250.,   200.,   100.,   150.,\n",
       "           100.,   200.],\n",
       "        [  130.,   230.,   130.,   130.,   130.,   130.,   130.,   130.,   230.,\n",
       "           130.,   100.,   100., -2900.,   200.,   250.,   200.,   100.,   150.,\n",
       "           100.,   200.],\n",
       "        [  260.,   460.,   260.,   260.,   260.,   260.,   260.,   260.,   460.,\n",
       "           260.,   200.,   200.,   200., -5600.,   500.,   400.,   200.,   300.,\n",
       "           200.,   400.],\n",
       "        [  325.,   575.,   325.,   325.,   325.,   325.,   325.,   325.,   575.,\n",
       "           325.,   250.,   250.,   250.,   500., -6875.,   500.,   250.,   375.,\n",
       "           250.,   500.],\n",
       "        [  260.,   460.,   260.,   260.,   260.,   260.,   260.,   260.,   460.,\n",
       "           260.,   200.,   200.,   200.,   400.,   500., -5600.,   200.,   300.,\n",
       "           200.,   400.],\n",
       "        [  130.,   230.,   130.,   130.,   130.,   130.,   130.,   130.,   230.,\n",
       "           130.,   100.,   100.,   100.,   200.,   250.,   200., -2900.,   150.,\n",
       "           100.,   200.],\n",
       "        [  195.,   345.,   195.,   195.,   195.,   195.,   195.,   195.,   345.,\n",
       "           195.,   150.,   150.,   150.,   300.,   375.,   300.,   150., -4275.,\n",
       "           150.,   300.],\n",
       "        [  130.,   230.,   130.,   130.,   130.,   130.,   130.,   130.,   230.,\n",
       "           130.,   100.,   100.,   100.,   200.,   250.,   200.,   100.,   150.,\n",
       "         -2900.,   200.],\n",
       "        [  260.,   460.,   260.,   260.,   260.,   260.,   260.,   260.,   460.,\n",
       "           260.,   200.,   200.,   200.,   400.,   500.,   400.,   200.,   300.,\n",
       "           200., -5600.]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem.Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([25, 7,13, 31, 42,17, 21,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27556"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "166**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3731.,   299.,   169.,   169.,   169.,   169.,   169.,   169.,\n",
       "          299.,   169.,   130.,   130.,   130.,   260.,   325.,   260.,\n",
       "          130.,   195.,   130.,   260.],\n",
       "       [  299., -6371.,   299.,   299.,   299.,   299.,   299.,   299.,\n",
       "          529.,   299.,   230.,   230.,   230.,   460.,   575.,   460.,\n",
       "          230.,   345.,   230.,   460.],\n",
       "       [  169.,   299., -3731.,   169.,   169.,   169.,   169.,   169.,\n",
       "          299.,   169.,   130.,   130.,   130.,   260.,   325.,   260.,\n",
       "          130.,   195.,   130.,   260.],\n",
       "       [  169.,   299.,   169., -3731.,   169.,   169.,   169.,   169.,\n",
       "          299.,   169.,   130.,   130.,   130.,   260.,   325.,   260.,\n",
       "          130.,   195.,   130.,   260.],\n",
       "       [  169.,   299.,   169.,   169., -3731.,   169.,   169.,   169.,\n",
       "          299.,   169.,   130.,   130.,   130.,   260.,   325.,   260.,\n",
       "          130.,   195.,   130.,   260.],\n",
       "       [  169.,   299.,   169.,   169.,   169., -3731.,   169.,   169.,\n",
       "          299.,   169.,   130.,   130.,   130.,   260.,   325.,   260.,\n",
       "          130.,   195.,   130.,   260.],\n",
       "       [  169.,   299.,   169.,   169.,   169.,   169., -3731.,   169.,\n",
       "          299.,   169.,   130.,   130.,   130.,   260.,   325.,   260.,\n",
       "          130.,   195.,   130.,   260.],\n",
       "       [  169.,   299.,   169.,   169.,   169.,   169.,   169., -3731.,\n",
       "          299.,   169.,   130.,   130.,   130.,   260.,   325.,   260.,\n",
       "          130.,   195.,   130.,   260.],\n",
       "       [  299.,   529.,   299.,   299.,   299.,   299.,   299.,   299.,\n",
       "        -6371.,   299.,   230.,   230.,   230.,   460.,   575.,   460.,\n",
       "          230.,   345.,   230.,   460.],\n",
       "       [  169.,   299.,   169.,   169.,   169.,   169.,   169.,   169.,\n",
       "          299., -3731.,   130.,   130.,   130.,   260.,   325.,   260.,\n",
       "          130.,   195.,   130.,   260.],\n",
       "       [  130.,   230.,   130.,   130.,   130.,   130.,   130.,   130.,\n",
       "          230.,   130., -2900.,   100.,   100.,   200.,   250.,   200.,\n",
       "          100.,   150.,   100.,   200.],\n",
       "       [  130.,   230.,   130.,   130.,   130.,   130.,   130.,   130.,\n",
       "          230.,   130.,   100., -2900.,   100.,   200.,   250.,   200.,\n",
       "          100.,   150.,   100.,   200.],\n",
       "       [  130.,   230.,   130.,   130.,   130.,   130.,   130.,   130.,\n",
       "          230.,   130.,   100.,   100., -2900.,   200.,   250.,   200.,\n",
       "          100.,   150.,   100.,   200.],\n",
       "       [  260.,   460.,   260.,   260.,   260.,   260.,   260.,   260.,\n",
       "          460.,   260.,   200.,   200.,   200., -5600.,   500.,   400.,\n",
       "          200.,   300.,   200.,   400.],\n",
       "       [  325.,   575.,   325.,   325.,   325.,   325.,   325.,   325.,\n",
       "          575.,   325.,   250.,   250.,   250.,   500., -6875.,   500.,\n",
       "          250.,   375.,   250.,   500.],\n",
       "       [  260.,   460.,   260.,   260.,   260.,   260.,   260.,   260.,\n",
       "          460.,   260.,   200.,   200.,   200.,   400.,   500., -5600.,\n",
       "          200.,   300.,   200.,   400.],\n",
       "       [  130.,   230.,   130.,   130.,   130.,   130.,   130.,   130.,\n",
       "          230.,   130.,   100.,   100.,   100.,   200.,   250.,   200.,\n",
       "        -2900.,   150.,   100.,   200.],\n",
       "       [  195.,   345.,   195.,   195.,   195.,   195.,   195.,   195.,\n",
       "          345.,   195.,   150.,   150.,   150.,   300.,   375.,   300.,\n",
       "          150., -4275.,   150.,   300.],\n",
       "       [  130.,   230.,   130.,   130.,   130.,   130.,   130.,   130.,\n",
       "          230.,   130.,   100.,   100.,   100.,   200.,   250.,   200.,\n",
       "          100.,   150., -2900.,   200.],\n",
       "       [  260.,   460.,   260.,   260.,   260.,   260.,   260.,   260.,\n",
       "          460.,   260.,   200.,   200.,   200.,   400.,   500.,   400.,\n",
       "          200.,   300.,   200., -5600.]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3525.,   175.,   325.,   775.,  1050.,   425.,   525.,   250.],\n",
       "       [    0., -1113.,    91.,   217.,   294.,   119.,   147.,    70.],\n",
       "       [    0.,     0., -1989.,   403.,   546.,   221.,   273.,   130.],\n",
       "       [    0.,     0.,     0., -4185.,  1302.,   527.,   651.,   310.],\n",
       "       [    0.,     0.,     0.,     0., -5208.,   714.,   882.,   420.],\n",
       "       [    0.,     0.,     0.,     0.,     0., -2533.,   357.,   170.],\n",
       "       [    0.,     0.,     0.,     0.,     0.,     0., -3045.,   210.],\n",
       "       [    0.,     0.,     0.,     0.,     0.,     0.,     0., -1560.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.triu(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max pop fitness: 0.0, Mean pop fitness : -694.02001953125\n",
      "Learning from population\n",
      "Optimising population\n",
      "Max pop fitness: 0.0, Mean pop fitness : -588.2000122070312\n",
      "Evaluations: 920\n",
      "Learning from population\n",
      "Optimising population\n",
      "Max pop fitness: 0.0, Mean pop fitness : -186.89999389648438\n",
      "Evaluations: 2772\n",
      "Learning from population\n",
      "Optimising population\n",
      "Max pop fitness: 0.0, Mean pop fitness : -104.0199966430664\n",
      "Evaluations: 5481\n",
      "Learning from population\n",
      "Optimising population\n",
      "Max pop fitness: 0.0, Mean pop fitness : -55.380001068115234\n",
      "Evaluations: 9086\n",
      "Learning from population\n",
      "Optimising population\n",
      "Max pop fitness: 0.0, Mean pop fitness : 0.0\n",
      "Evaluations: 13589\n",
      "Learning from population\n",
      "Optimising population\n",
      "Max pop fitness: 0.0, Mean pop fitness : 0.0\n",
      "Evaluations: 18989\n",
      "Learning from population\n",
      "Optimising population\n",
      "Max pop fitness: 0.0, Mean pop fitness : 0.0\n",
      "Evaluations: 24389\n",
      "Learning from population\n",
      "Optimising population\n",
      "Max pop fitness: 0.0, Mean pop fitness : 0.0\n",
      "Evaluations: 29789\n",
      "Learning from population\n",
      "Optimising population\n",
      "Max pop fitness: 0.0, Mean pop fitness : 0.0\n",
      "Evaluations: 35189\n",
      "Learning from population\n",
      "Optimising population\n",
      "Max pop fitness: 0.0, Mean pop fitness : 0.0\n",
      "Evaluations: 40589\n",
      "Learning from population\n",
      "Optimising population\n",
      "Max pop fitness: 0.0, Mean pop fitness : 0.0\n",
      "Evaluations: 45989\n",
      "Learning from population\n",
      "Optimising population\n",
      "Max pop fitness: 0.0, Mean pop fitness : 0.0\n",
      "Evaluations: 51389\n",
      "Learning from population\n",
      "Optimising population\n",
      "Max pop fitness: 0.0, Mean pop fitness : 0.0\n",
      "Evaluations: 56789\n",
      "Learning from population\n",
      "Optimising population\n",
      "Max pop fitness: 0.0, Mean pop fitness : 0.0\n",
      "Evaluations: 62189\n",
      "Learning from population\n",
      "Optimising population\n",
      "Max pop fitness: 0.0, Mean pop fitness : 0.0\n",
      "Evaluations: 67589\n",
      "Learning from population\n",
      "Optimising population\n",
      "Max pop fitness: 0.0, Mean pop fitness : 0.0\n",
      "Evaluations: 72989\n",
      "Learning from population\n",
      "Optimising population\n",
      "Max pop fitness: 0.0, Mean pop fitness : 0.0\n",
      "Evaluations: 78389\n",
      "Learning from population\n",
      "Optimising population\n",
      "Max pop fitness: 0.0, Mean pop fitness : 0.0\n",
      "Evaluations: 83789\n",
      "Learning from population\n",
      "Optimising population\n",
      "Max pop fitness: 0.0, Mean pop fitness : 0.0\n",
      "Evaluations: 89189\n",
      "Learning from population\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLearning from population\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Learing with the entire population as a batch is technically not the best from a machine learning perspective,\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# but does not seem to have a massive impact on solution quality whilst also increasing learning speed significantly.\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[43mhandler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn_from_population\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml1_coef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml1_coef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpop_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimising population\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m population, fitnesses, evaluations, done \u001b[38;5;241m=\u001b[39m handler\u001b[38;5;241m.\u001b[39moptimise_solutions(\n\u001b[1;32m     41\u001b[0m     population, fitnesses, change_tolerance, encode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, repair_solutions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, deepest_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     42\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/UoM/ERP/MscDissertation/Deep-Opt/OptimAE.py:54\u001b[0m, in \u001b[0;36mOptimAEHandler.learn_from_population\u001b[0;34m(self, solutions, optimizer, l1_coef, batch_size, epochs, print_loss)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i,x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset):\n\u001b[0;32m---> 54\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn_from_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml1_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m         total_recon \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecon\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m print_loss:\n",
      "File \u001b[0;32m~/Documents/UoM/ERP/MscDissertation/Deep-Opt/Models/DOAE.py:227\u001b[0m, in \u001b[0;36mDOAE.learn_from_sample\u001b[0;34m(self, x, optimizer, l1_coef)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    226\u001b[0m output, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(x)\n\u001b[0;32m--> 227\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml1_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    230\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/Documents/UoM/ERP/MscDissertation/Deep-Opt/Models/DOAE.py:205\u001b[0m, in \u001b[0;36mDOAE.loss\u001b[0;34m(self, x, recon, l1_coef)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03mCalculates the loss function. This is done by adding the MSE of the input and the \u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03mreconstruction given by the AE, as well as an L1 term multiplied by a coefficient.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m    The loss dictionary containing the total loss, reconstruction error and L1 loss.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    204\u001b[0m mse \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(x, recon)\n\u001b[0;32m--> 205\u001b[0m l1_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m loss \u001b[38;5;241m=\u001b[39m mse \u001b[38;5;241m+\u001b[39m l1_coef \u001b[38;5;241m*\u001b[39m l1_loss\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m : loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecon\u001b[39m\u001b[38;5;124m\"\u001b[39m : mse, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m\"\u001b[39m : l1_loss}\n",
      "File \u001b[0;32m~/Documents/UoM/ERP/MscDissertation/Deep-Opt/Models/DOAE.py:205\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03mCalculates the loss function. This is done by adding the MSE of the input and the \u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03mreconstruction given by the AE, as well as an L1 term multiplied by a coefficient.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m    The loss dictionary containing the total loss, reconstruction error and L1 loss.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    204\u001b[0m mse \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(x, recon)\n\u001b[0;32m--> 205\u001b[0m l1_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[1;32m    206\u001b[0m loss \u001b[38;5;241m=\u001b[39m mse \u001b[38;5;241m+\u001b[39m l1_coef \u001b[38;5;241m*\u001b[39m l1_loss\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m : loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecon\u001b[39m\u001b[38;5;124m\"\u001b[39m : mse, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m\"\u001b[39m : l1_loss}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "change_tolerance = Q.shape[0]\n",
    "problem_size = Q.shape[0]\n",
    "pop_size = 100\n",
    "\n",
    "dropout_prob = 0.2\n",
    "# 1000 bit QUBO l1 and l2:\n",
    "# l1_coef = 0.0000025\n",
    "# l2_coef = 0.0000025\n",
    "# 500 bit QUBO l1 and l2:\n",
    "# l1_coef = 0.000005\n",
    "# l2_coef = 0.000005\n",
    "# 100 bit l1 and l2\n",
    "l1_coef = 0.0001\n",
    "l2_coef = 0.0001\n",
    "lr = 0.002\n",
    "compression_ratio = 0.8\n",
    "model = DOAE(problem_size, dropout_prob, device)\n",
    "hidden_size = problem_size\n",
    "handler = OptimAEHandler(model, problem, device)\n",
    "\n",
    "population, fitnesses = handler.generate_population(pop_size)\n",
    "population, fitnesses, _, _ = handler.hillclimb(population, fitnesses, change_tolerance)\n",
    "handler.print_statistics(fitnesses)\n",
    "\n",
    "total_eval = 0\n",
    "max_depth = 6\n",
    "depth = 0\n",
    "\n",
    "while True:\n",
    "    if depth < max_depth:\n",
    "        hidden_size = round(hidden_size * compression_ratio)\n",
    "        model.transition(hidden_size)\n",
    "        depth += 1\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_coef)\n",
    "    print(\"Learning from population\")\n",
    "    # Learing with the entire population as a batch is technically not the best from a machine learning perspective,\n",
    "    # but does not seem to have a massive impact on solution quality whilst also increasing learning speed significantly.\n",
    "    handler.learn_from_population(population, optimizer, l1_coef=l1_coef, batch_size=pop_size)\n",
    "    print(\"Optimising population\")\n",
    "    population, fitnesses, evaluations, done = handler.optimise_solutions(\n",
    "        population, fitnesses, change_tolerance, encode=True, repair_solutions=True, deepest_only=False\n",
    "    )\n",
    "    handler.print_statistics(fitnesses)\n",
    "    total_eval += evaluations\n",
    "    print(\"Evaluations: {}\".format(total_eval))\n",
    "    \n",
    "    # Uncomment lines below to print out best solution at every transition\n",
    "    # best_i = torch.argmax(fitnesses)\n",
    "    # print(\"Best solution - fitness = {}\".format(fitnesses[best_i].item()))\n",
    "    # print(population[best_i].tolist())\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1., -1., -1., -1., -1., -1., -1.])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508.,\n",
       "        4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508.,\n",
       "        4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508.,\n",
       "        4508., 4508., 4508., 4508., 4508., 4508., 4508., 3324., 4508., 4508.,\n",
       "        4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508.,\n",
       "        4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508.,\n",
       "        4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508.,\n",
       "        4508., 4508., 4508., 3068., 4508., 4508., 4508., 4508., 4508., 4508.,\n",
       "        4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508.,\n",
       "        4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508., 4508.])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.,  1., -1., -1.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4, 4, 4, 4]), tensor([4, 4, 4, 4]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.count_nonzero(problem.Q, dim=0), torch.count_nonzero(problem.Q, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4]), tensor([4, 3, 2, 1]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.count_nonzero(Q_tensor, dim=0), torch.count_nonzero(Q_tensor, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  -0., -529., -736., -920.], dtype=torch.float64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_tensor[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-598., -529., -736., -920.])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem.Q[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
